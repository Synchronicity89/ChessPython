{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PyLinq import PyLinqData\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Move tensor to the GPU\n",
    "x = torch.tensor([1.0])\n",
    "x = x.to(device)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to train a simple neural network with an \n",
    "# input layer of 71 doubles and middle layer of 101 doubles and an output layer of 71 doubles\n",
    "# we will use the sigmoid function as the activation function\n",
    "# we will use the mean squared error as the loss function\n",
    "# we will use the stochastic gradient descent as the optimization algorithm\n",
    "# we will use the learning rate of 0.01\n",
    "# we will use the batch size of 100\n",
    "# we will use the number of epochs of 100\n",
    "# we will use the random seed of 42\n",
    "# will import the training dat from the file \"x_training.csv\" in the same folder as this notebook\n",
    "# will import the target data from the file \"y_labels.csv\" in the same folder as this notebook\n",
    "# we will save the trained model to the file \"model.pt\" in the same folder as this notebook\n",
    "# we will save the loss history to the file \"loss_history.csv\" in the same folder as this notebook\n",
    "# we will save the accuracy history to the file \"accuracy_history.csv\" in the same folder as this notebook\n",
    "# we will save the training history to the file \"training_history.csv\" in the same folder as this notebook\n",
    "# we will save the validation history to the file \"validation_history.csv\" in the same folder as this notebook\n",
    "# we will save the test history to the file \"test_history.csv\" in the same folder as this notebook\n",
    "# we will save the confusion matrix to the file \"confusion_matrix.csv\" in the same folder as this notebook\n",
    "\n",
    "# import the libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set the random seed\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# load the data\n",
    "x = pd.read_csv(\"../x_training.csv\")\n",
    "y = pd.read_csv(\"../y_labels.csv\")\n",
    "\n",
    "# The training data consists of doubles.  The first 64 columns of input data have only a few possible values.  Examine the first 64 columns and find out all the possible values that can be found in those columns.\n",
    "uniqueValus = x.iloc[:, 0:64].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the unique values with some explanation of what they are and their frequency in each of the 64 columns\n",
    "print(\"The first 64 columns of the input data have the following unique values\")\n",
    "# create a concatenation of the input to the output data in a separate 2D numpy array\n",
    "x = x.to_numpy()\n",
    "y = y.to_numpy()\n",
    "# concatenate x and y into a single 2D numpy array\n",
    "data = np.concatenate((x, y), axis=1)\n",
    "# make sure the data is in the correct format\n",
    "data = data.astype(float)\n",
    "\n",
    "# # convert the data into ordinal encoding for all columns\n",
    "# for i in range(0, 71):\n",
    "#     uniqueValues = np.unique(data[:, i]) # this line finds the unique values in the column\n",
    "#     for j in range(0, len(uniqueValues)):\n",
    "#         data[:, i] = np.where(data[:, i] == uniqueValues[j], j, data[:, i])\n",
    "\n",
    "# # validate the conversion by converting the data back to the original values and comparing the original and converted data\n",
    "# for i in range(0, 71):\n",
    "#     uniqueValues = np.unique(x[:, i])\n",
    "#     for j in range(0, len(uniqueValues)):\n",
    "#         x[:, i] = np.where(x[:, i] == j, uniqueValues[j], x[:, i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(uniqueValues)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train an autoencoder to reduce the dimensionality of the input data\n",
    "# the input data has 71 columns\n",
    "# the output data has 71 columns\n",
    "# the middle layer has 44 columns\n",
    "# the activation function is the sigmoid function\n",
    "# the loss function is the mean squared error\n",
    "# the optimization algorithm is the stochastic gradient descent\n",
    "# the learning rate is 0.05 and the batch size is 100\n",
    "# the number of epochs is 100\n",
    "# the random seed is 42\n",
    "# the model is saved to the file \"autoencoder.pt\"\n",
    "# the loss history is saved to the file \"autoencoder_loss_history.csv\"\n",
    "\n",
    "# create the autoencoder class\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(71, 500),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(500, 71),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# create the autoencoder\n",
    "autoencoder = Autoencoder()\n",
    "autoencoder.to(device)\n",
    "\n",
    "# create the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# create the optimizer\n",
    "optimizer = optim.SGD(autoencoder.parameters(), lr=0.04)\n",
    "\n",
    "# create the data loader\n",
    "dataLoader = torch.utils.data.DataLoader(x, batch_size=100, shuffle=True)\n",
    "\n",
    "# train the autoencoder\n",
    "lossHistory = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(1000):\n",
    "    for i, data in enumerate(dataLoader, 0):\n",
    "        inputs = data\n",
    "        inputs = inputs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = autoencoder(inputs.float())\n",
    "        loss = criterion(outputs.float(), inputs.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    lossHistory.append(loss.item())\n",
    "    print(\"Epoch: \", epoch, \" Loss: \", loss.item())\n",
    "\n",
    "# save the autoencoder\n",
    "torch.save(autoencoder.state_dict(), \"autoencoder.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the loss history\n",
    "lossHistory = pd.DataFrame(lossHistory, columns=[\"Loss\"])\n",
    "\n",
    "lossHistory.to_csv(\"autoencoder_loss_history.csv\", index=False)\n",
    "\n",
    "# plot the loss history\n",
    "plt.plot(lossHistory)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Autoencoder Loss History\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a random single input from the input data and use the trained autoencoder to encode and decode the input\n",
    "# print the original input and the encoded and decoded input\n",
    "# choose a random input\n",
    "input = x[0, :]\n",
    "# encode and decode the input\n",
    "input = torch.tensor(input)\n",
    "input = input.to(device)\n",
    "output = autoencoder(input.float())\n",
    "output = output.cpu().detach().numpy()\n",
    "input = input.cpu().detach().numpy()\n",
    "print(\"Original Input: \", input)\n",
    "print(\"Output: \", output)   \n",
    "\n",
    "# train a neural network to classify the input data\n",
    "# the input data has 71 columns\n",
    "# the output data has 71 columns\n",
    "# the middle layer has 101 columns\n",
    "# the activation function is the sigmoid function\n",
    "# the loss function is the mean squared error\n",
    "# the optimization algorithm is the stochastic gradient descent\n",
    "# the learning rate is 0.01 and the batch size is 100\n",
    "# the number of epochs is 500\n",
    "# the random seed is 42\n",
    "# the model is saved to the file \"model.pt\"\n",
    "\n",
    "# create the neural network class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(71, 101)\n",
    "        self.layer2 = nn.Linear(101, 71)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "# create the neural network\n",
    "neuralNetwork = NeuralNetwork()\n",
    "neuralNetwork.to(device)\n",
    "\n",
    "# create the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# create the optimizer\n",
    "optimizer = optim.SGD(neuralNetwork.parameters(), lr=0.11)\n",
    "\n",
    "# create the data loader\n",
    "dataLoader = torch.utils.data.DataLoader(x, batch_size=100, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train the neural network\n",
    "lossHistory = []\n",
    "for epoch in range(500):\n",
    "    for i, data in enumerate(dataLoader, 0):\n",
    "        inputs = data\n",
    "        inputs = inputs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = neuralNetwork(inputs.float())\n",
    "        loss = criterion(outputs.float(), inputs.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    lossHistory.append(loss.item())\n",
    "    print(\"Epoch: \", epoch, \" Loss: \", loss.item())\n",
    "\n",
    "# save the neural network\n",
    "torch.save(neuralNetwork.state_dict(), \"model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the loss history\n",
    "lossHistory = pd.DataFrame(lossHistory, columns=[\"Loss\"])\n",
    "lossHistory.to_csv(\"loss_history.csv\", index=False)\n",
    "\n",
    "# plot the loss history\n",
    "plt.plot(lossHistory)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss History\")\n",
    "plt.show()\n",
    "\n",
    "# choose a random single input from the input data and use the trained neural network to predict the output\n",
    "# print the original input and the predicted output\n",
    "# choose a random input\n",
    "input = x[0, :]\n",
    "# predict the output\n",
    "input = torch.tensor(input)\n",
    "\n",
    "input = input.to(device)\n",
    "output = neuralNetwork(input.float())\n",
    "output = output.cpu().detach().numpy()\n",
    "input = input.cpu().detach().numpy()\n",
    "print(\"Original Input: \", input)\n",
    "print(\"Output: \", output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function to add the enpassant target rows\n",
    "def addEnpassantTargets(origRow, fen, i):\n",
    "    # create a string to represent the row\n",
    "    # throw an error if i is not 2 or 6\n",
    "    if(i != 2 and i != 5):\n",
    "        raise ValueError(\"i must be 2 or 6\")\n",
    "    row = origRow\n",
    "    if(fen[3] != \"-\"):\n",
    "        if(int(fen[3][1]) == i + 1 or int(fen[3][1]) == i):\n",
    "            cols = \"abcdefgh\"\n",
    "            index = cols.index(fen[3][0])\n",
    "            # use the simplest notation to replace the character at the index with the t character\n",
    "            row = row[:index] + (\"t\" if i == 2 else \"T\") + row[index + 1:]\n",
    "    # set row to the 8 char substring of all starting at side * 8\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  KQkq  Converted:  KQkq  Reverted:  KQkq\n",
      "Original:  Kkq  Converted:  K-kq  Reverted:  Kkq\n",
      "Original:  KQk  Converted:  KQk-  Reverted:  KQk\n",
      "Original:  KQ  Converted:  KQ--  Reverted:  KQ\n",
      "Original:  K  Converted:  K---  Reverted:  K\n",
      "Original:  Q  Converted:  -Q--  Reverted:  Q\n",
      "Original:  k  Converted:  --k-  Reverted:  k\n",
      "Original:  q  Converted:  ---q  Reverted:  q\n",
      "Original:  -  Converted:  ----  Reverted:  -\n"
     ]
    }
   ],
   "source": [
    "def castlingRightsToString(castlingRights):\n",
    "    # Define the order of castling rights as they should appear in the string\n",
    "    orderedRights = \"KQkq\"\n",
    "    # Use list comprehension to check for each right in orderedRights and replace with \"-\" if absent\n",
    "    return ''.join(c if c in castlingRights else '-' for c in orderedRights)\n",
    "\n",
    "def revertCastlingRights(paddedRights):\n",
    "    # Filter out '-' characters and join the remaining characters to form the castling rights part of FEN\n",
    "    castlingRights = ''.join(c for c in paddedRights if c != '-')\n",
    "    # Return a dash if there are no castling rights, otherwise return the castling rights string\n",
    "    return castlingRights if castlingRights else '-'\n",
    "\n",
    "# test these functions with a variety of inputs such as KQkq, Kkq, KQk, KQ, K, Q, k, q, and the empty string\n",
    "# create a list of standard FEN castling rights strings which are variable length\n",
    "castlingRights = [\"KQkq\", \"Kkq\", \"KQk\", \"KQ\", \"K\", \"Q\", \"k\", \"q\", \"-\"]\n",
    "# use the map function to apply the function to each element of the list and then back again and compare the final result with the original\n",
    "# loop through each string in the list and outpt the result of the function and the original string to the console\n",
    "convertedRights = list(map(castlingRightsToString, castlingRights))\n",
    "revertedRights = list(map(revertCastlingRights, convertedRights))\n",
    "# go throough each string in the list and print the original string and the result of the function in detail\n",
    "for i in range(len(castlingRights)):\n",
    "    print(\"Original: \", castlingRights[i], \" Converted: \", convertedRights[i], \" Reverted: \", revertedRights[i])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generate some new categorical data for a new neural network\n",
    "# the new data has enough columns to represent a variation of FEN notation for a chess board, where the / is left out because\n",
    "# each row is represented in full without any compression of the empty squares\n",
    "# here is an example of a normal FEN notation: rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n",
    "# define a function to take the normal notation and convert it to a 64 column representation without slashes plus\n",
    "# The full move and half move counts are discarded, but the move turn and castling rights are preserved\n",
    "# here is an example of the conversion of the starting position: rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1 to the new format\n",
    "# rnbqkbnrpppppppp00000000000000000000000000000000PPPPPPPPRNBQKBNRwKQkq\n",
    "# the first 64 columns represent the board, and the last 5 columns represent the move turn and castling rights\n",
    "# the new data has 69 columns\n",
    "def convertFEN(fen):\n",
    "    # split the FEN into its 6 components\n",
    "    fen = fen.split(\" \")\n",
    "    # split the board into its 8 rows\n",
    "    board = fen[0].split(\"/\")\n",
    "    # create a new board with the rows combined and the empty squares compressed\n",
    "    newBoard = \"\"\n",
    "    for i in range(0, 8):\n",
    "        # call a function to add the enpassant target rows if i has the value of 2 or 5\n",
    "        for j in range(0, len(board[i])):\n",
    "            if board[i][j].isdigit():\n",
    "                for k in range(0, int(board[i][j])):\n",
    "                    newBoard += \"0\"\n",
    "            else:\n",
    "                newBoard += board[i][j]\n",
    "        if i == 2 or i == 5:\n",
    "            # pass the last 8 chars of newBoard into the enpassant function, then replace the last 8 chars of newBoard with the result\n",
    "            newBoard = newBoard[:-8] + addEnpassantTargets(newBoard[-8:], fen, i)\n",
    "            \n",
    "\n",
    "    # add the columns for move turn and castling rights\n",
    "    newBoard += fen[1] + castlingRightsToString(fen[2])\n",
    "    return newBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1bqkbnr/ppp1pppp/n7/3pP3/8/304/PPPP1PPP/RNBQKBNR w KQkq d3\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def revertFEN(customFEN):\n",
    "    # Extract the board part and metadata from the custom FEN\n",
    "    boardPart, moveTurn, paddedRights = customFEN[:64], customFEN[64], customFEN[65:]\n",
    "    \n",
    "    # Initialize variables for en passant target\n",
    "    enPassantTarget = \"-\"\n",
    "    reconstructedBoard = \"\"\n",
    "    \n",
    "    # Reconstruct the board\n",
    "    for i in range(8):\n",
    "        row = boardPart[i*8:(i+1)*8]\n",
    "        newRow = \"\"\n",
    "        emptyCount = 0\n",
    "        for j, char in enumerate(row):\n",
    "            if char == '0':\n",
    "                emptyCount += 1\n",
    "            elif char == 't' or char == 'T':  # Handle en passant target\n",
    "                if emptyCount > 0:\n",
    "                    newRow += str(emptyCount)\n",
    "                    emptyCount = 0\n",
    "                newRow += '0'  # Replace 't' with '0' for now, as we handle en passant separately\n",
    "                # Determine the en passant square\n",
    "                cols = \"abcdefgh\"\n",
    "                enPassantTarget = cols[j] + str(6 if i == 3 else 3)  # Adjust rank based on the row\n",
    "            else:\n",
    "                if emptyCount > 0:\n",
    "                    newRow += str(emptyCount)\n",
    "                    emptyCount = 0\n",
    "                newRow += char\n",
    "        if emptyCount > 0:  # Handle trailing empty squares in a row\n",
    "            newRow += str(emptyCount)\n",
    "        reconstructedBoard += newRow + \"/\" if i < 7 else newRow  # Avoid adding '/' after the last row\n",
    "    \n",
    "    # Revert castling rights\n",
    "    castlingRights = revertCastlingRights(paddedRights)\n",
    "    \n",
    "    # Assemble the FEN including en passant target, without move numbers\n",
    "    return f\"{reconstructedBoard} {moveTurn} {castlingRights} {enPassantTarget}\"\n",
    "\n",
    "# Example usage\n",
    "customFEN = \"r0bqkbnrppp0ppppn0000000000pP00000000000000t0000PPPP0PPPRNBQKBNRwKQkq\"\n",
    "assert len(customFEN) == 69 # 64 for the board, 1 for move turn, 4 for castling rights\n",
    "print(revertFEN(customFEN))\n",
    "print(revertFEN(customFEN) in \"r1bqkbnr/ppp1pppp/n7/3pP3/8/8/PPPP1PPP/RNBQKBNR w KQkq d6 0 3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0bqkbnrppp0ppppn0000000000pP00000000000000T0000PPPP0PPPRNBQKBNRwKQkq\n",
      "r0bqkbnrppp0p0ppn00P00t00000000000000pP0N0000000PPPP0P0PR0BQKBNRbKQkq\n",
      "rnbqkbnrpppppppp00000000000000000000000000000000PPPPPPPPRNBQKBNRwKQkq\n",
      "00kr0bnrpppqp0ppn00P000000000b00000P0B00N00000p0PPPQ0P0PR000KBNRwKQ--\n"
     ]
    }
   ],
   "source": [
    "# test the function on the starting position\n",
    "# test with a different FEN where a move sequence E2E4, etc that leads to a board position where enpassant is possible\n",
    "fen1 = \"r1bqkbnr/ppp1pppp/n7/3pP3/8/8/PPPP1PPP/RNBQKBNR w KQkq d6 0 3\"\n",
    "newBoard1 = convertFEN(fen1)\n",
    "print(newBoard1)\n",
    "\n",
    "fen2 = \"r1bqkbnr/ppp1p1pp/n2P4/8/5pP1/N7/PPPP1P1P/R1BQKBNR b KQkq g3 0 5\"\n",
    "newBoard2 = convertFEN(fen2)\n",
    "print(newBoard2)\n",
    "\n",
    "fen3 = \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\"\n",
    "newBoard3 = convertFEN(fen3)\n",
    "print(newBoard3)\n",
    "\n",
    "fen4 = \"2kr1bnr/pppqp1pp/n2P4/5b2/3P1B2/N5p1/PPPQ1P1P/R3KBNR w KQ - 5 9\"\n",
    "newBoard4 = convertFEN(fen4)\n",
    "print(newBoard4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           CustomFEN\n",
      "0  rnbqkbnrpppppppp000000000000000000000000000000...\n",
      "1  rnbqkbnrpppppppp00000000000000000000P000000000...\n",
      "2  r0bqkbnrppppppppn0000000000000000000P000000000...\n",
      "3  r0bqkbnrppppppppn00000000000P00000000000000000...\n",
      "4  r0bqkbnrppp0ppppn0000000000pP00000000000000T00...\n",
      "                                           CustomFEN\n",
      "0  rnbqkbnrpppppppp00000000000000000000P000000000...\n",
      "1  r0bqkbnrppppppppn0000000000000000000P000000000...\n",
      "2  r0bqkbnrppppppppn00000000000P00000000000000000...\n",
      "3  r0bqkbnrppp0ppppn0000000000pP00000000000000T00...\n",
      "4  r0bqkbnrppp0ppppn00P00000000000000000000000000...\n"
     ]
    }
   ],
   "source": [
    "#!pip install python-chess\n",
    "import chess\n",
    "import chess.pgn\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Assuming convertFEN is defined as before and working correctly\n",
    "\n",
    "# Sample PGN string for demonstration\n",
    "pgn_string = \"\"\"\n",
    "[Event \"NicosiaKyrenia's Study: Enpassant\"]\n",
    "[Site \"https://lichess.org/study/WCSL1Ul1/YZoxPnWI\"]\n",
    "[Result \"*\"]\n",
    "[Variant \"Standard\"]\n",
    "[ECO \"B00\"]\n",
    "[Opening \"Lemming Defense\"]\n",
    "[Annotator \"https://lichess.org/@/NicosiaKyrenia\"]\n",
    "[UTCDate \"2024.02.18\"]\n",
    "[UTCTime \"01:03:04\"]\n",
    "\n",
    "1. e4 Na6 2. e5 d5 3. exd6 f5 4. Na3 f4 5. g4 fxg3 *\n",
    "\"\"\"\n",
    "\n",
    "# Initialize pandas DataFrames for training data and labels\n",
    "training_data = pd.DataFrame(columns=['CustomFEN'])\n",
    "labels_data = pd.DataFrame(columns=['CustomFEN'])\n",
    "\n",
    "# Read the PGN\n",
    "pgn = io.StringIO(pgn_string)\n",
    "game = chess.pgn.read_game(pgn)\n",
    "\n",
    "# Initialize a board from the game\n",
    "board = game.board()\n",
    "\n",
    "for move in game.mainline_moves():\n",
    "    # Generate standard FEN before the move\n",
    "    fen_before = board.fen()\n",
    "    # Convert to custom FEN and store as training data\n",
    "    custom_fen_before = convertFEN(fen_before)\n",
    "    training_data = pd.concat([training_data, pd.DataFrame({'CustomFEN': [custom_fen_before]})], ignore_index=True)\n",
    "    \n",
    "    # Apply the move on the board\n",
    "    board.push(move)\n",
    "    \n",
    "    # Generate standard FEN after the move\n",
    "    fen_after = board.fen()\n",
    "    # Convert to custom FEN and store as label data\n",
    "    custom_fen_after = convertFEN(fen_after)\n",
    "    labels_data = pd.concat([labels_data, pd.DataFrame({'CustomFEN': [custom_fen_after]})], ignore_index=True)\n",
    "    # custom_fen_after = convertFEN(fen_after)\n",
    "    # labels_data = labels_data.append({'CustomFEN': custom_fen_after}, ignore_index=True)\n",
    "\n",
    "# For demonstration, print the first few rows of each DataFrame\n",
    "print(training_data.head())\n",
    "print(labels_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 square possibilities: ['R', 'N', 'B', 'Q', 'K', 'r', 'n', 'b', 'q', 'k', '0']\n",
      "Move turn possibilities: ['w', 'b']\n",
      "First castling right possibility (King-side for white): ['K', '-']\n"
     ]
    }
   ],
   "source": [
    "# This the following commented code is the general approach to go through the \n",
    "# training data and labels and convert the data to ordinal encoding\n",
    "# convert the data into ordinal encoding for all columns\n",
    "# for i in range(0, 69):\n",
    "#     uniqueValues = np.unique(training_data.iloc[:, i]) # this line finds the unique values in the column\n",
    "#     for j in range(0, len(uniqueValues)):\n",
    "#         training_data.iloc[:, i] = np.where(training_data.iloc[:, i] == uniqueValues[j], j, training_data.iloc[:, i])\n",
    "#         labels_data.iloc[:, i] = np.where(labels_data.iloc[:, i] == uniqueValues[j], j, labels_data.iloc[:, i])\n",
    "\n",
    "# however, it is possible to synthesize the possible unique values for each column keeping in mind these rules:\n",
    "# There are no pawns possible in rows 1 and 8\n",
    "# Bishops can only be only be in the same color square as the starting square (not sure if that will help with ordinal encoding)\n",
    "# There are only a few possible values for the castling rights and the move turn\n",
    "# The enpassant target can only be in rows 3 and 6\n",
    "# The enpassant target can only be in the same chess board column as the last move's pawn move (not sure if that will help with ordinal encoding)\n",
    "# define a function to synthesize the possible unique values for each column of the training data and labels\n",
    "# the function will return a list of the possible unique values for each column (don't know why it would be a list of lists)\n",
    "# the function uniqueValuesPossibleForColumn will take a record and the column index as input and return the possible unique values for that column\n",
    "# for i in range(0, 69):\n",
    "#     uniqueValues = uniqueValuesPossibleForColumn(training_data.iloc[0, :], i)\n",
    "\n",
    "def synthesize_custom_ordinal_values_final():\n",
    "    ordinal_values = {}\n",
    "\n",
    "    # Define all possible pieces, including uppercase for white and lowercase for black\n",
    "    pieces_general = ['R', 'N', 'B', 'Q', 'K', 'P', 'r', 'n', 'b', 'q', 'k', 'p', '0']\n",
    "    pieces_no_pawns = ['R', 'N', 'B', 'Q', 'K', 'r', 'n', 'b', 'q', 'k', '0']  # Exclude pawns in rows 1 and 8\n",
    "    pieces_en_passant = ['R', 'N', 'B', 'Q', 'K', 'P', 'r', 'n', 'b', 'q', 'k', 'p', '0', 'T', 't']  # Include 't' for en passant\n",
    "    \n",
    "    # Assign possible values for each board square\n",
    "    for i in range(64):\n",
    "        row = i // 8 + 1\n",
    "        if row in [1, 8]:\n",
    "            ordinal_values[i] = pieces_no_pawns\n",
    "        elif row in [3, 6]:  # Corrected rows for potential en passant targets, reflecting actual play possibilities\n",
    "            ordinal_values[i] = pieces_en_passant\n",
    "        else:\n",
    "            ordinal_values[i] = pieces_general\n",
    "\n",
    "    # Move turn possibilities\n",
    "    ordinal_values[64] = ['w', 'b']\n",
    "    \n",
    "    # Castling rights - specific to each right, with '-' indicating the absence of the right\n",
    "    ordinal_values[65] = ['K', '-']  # King-side for white\n",
    "    ordinal_values[66] = ['Q', '-']  # Queen-side for white\n",
    "    ordinal_values[67] = ['k', '-']  # King-side for black\n",
    "    ordinal_values[68] = ['q', '-']  # Queen-side for black\n",
    "    \n",
    "    return ordinal_values\n",
    "\n",
    "ordinal_values_final = synthesize_custom_ordinal_values_final()\n",
    "\n",
    "# Example of accessing possible values for specific squares or data points\n",
    "print(\"A1 square possibilities:\", ordinal_values_final[0])  # Example for A1 square\n",
    "print(\"Move turn possibilities:\", ordinal_values_final[64]) # Example for move turn\n",
    "print(\"First castling right possibility (King-side for white):\", ordinal_values_final[65]) # Example for first castling right\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test some of the custom FENs with the ordinal encoding to make sure the encoding is working correctly\n",
    "# for each custom FEN, go through each character and confirm that the character is in the possible unique values for that column\n",
    "# if it is not, print an error message\n",
    "\n",
    "for fen in [newBoard1, newBoard2, newBoard3, newBoard4]:\n",
    "    for i, char in enumerate(fen):\n",
    "        if char not in ordinal_values_final[i]:\n",
    "            print(f\"Error: {char} not in possible values for column {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path/to/training_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 74\u001b[0m\n\u001b[0;32m     71\u001b[0m training_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath/to/training_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     72\u001b[0m labels_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath/to/labels_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 74\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_csv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m train_loader, val_loader \u001b[38;5;241m=\u001b[39m create_dataloaders(X, y)\n",
      "Cell \u001b[1;32mIn[75], line 43\u001b[0m, in \u001b[0;36mload_and_preprocess_data\u001b[1;34m(training_csv, labels_csv)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_and_preprocess_data\u001b[39m(training_csv, labels_csv):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# Load the CSV files\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     training_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_csv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     labels_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(labels_csv)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# Convert FEN strings to custom format and then encode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\torchPlay\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\torchPlay\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\torchPlay\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\torchPlay\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\torchPlay\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/training_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Placeholder for the convertFEN function you provided earlier\n",
    "def convertFEN(fen):\n",
    "    # Your convertFEN function here\n",
    "    custom_fen = convertFEN(fen)\n",
    "    return custom_fen\n",
    "\n",
    "# Function to encode a custom FEN string to numerical format\n",
    "def encode_custom_fen(custom_fen):\n",
    "    # Implement the encoding logic here, using the ordinal_values mapping\n",
    "    # This is a placeholder function; you'll need to replace it with your actual encoding logic\n",
    "    # encoded = np.array([ordinal_values[char] for char in custom_fen])\n",
    "    # define a dictionary to hold the ordinal values for each piece.  Use negative numbers for black, and positive for white.\n",
    "    # pawns are 1, knights are 3, bishops 3.5, rooks 5, queens 9, and kings 15\n",
    "    pieceValues = {'R': 5, 'N': 3, 'B': 3.5, 'Q': 9, 'K': 15, 'P': 1, 'T': 1.3, 'r': -5, 'n': -3, 'b': -3.5, 'q': -9, 'k': -15, 'p': 1, 't': 1.3, '0': 0}\n",
    "    moveTurn = {'w': 1, 'b': -1}\n",
    "    castlingRights = {'K': 1, 'Q': 1, 'k': -1, 'q': -1, '-': 0}\n",
    "    # convert the custom FEN to a list of floats in a numpy array\n",
    "    encoded = np.array([pieceValues[char] for char in custom_fen[:64]] + [moveTurn[custom_fen[64]]] + [castlingRights[char] for char in custom_fen[65:]])\n",
    "    # make sure its a float array\n",
    "    encoded = encoded.astype(float)    \n",
    "\n",
    "    return encoded\n",
    "\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "def load_and_preprocess_data(training_csv, labels_csv):\n",
    "    # Load the CSV files\n",
    "    training_df = pd.read_csv(training_csv)\n",
    "    labels_df = pd.read_csv(labels_csv)\n",
    "    \n",
    "    # Convert FEN strings to custom format and then encode\n",
    "    training_data_encoded = [encode_custom_fen(convertFEN(fen)) for fen in training_df['FEN']]\n",
    "    labels_encoded = [encode_custom_fen(convertFEN(fen)) for fen in labels_df['FEN']]\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X = torch.tensor(training_data_encoded, dtype=torch.float32)\n",
    "    y = torch.tensor(labels_encoded, dtype=torch.float32)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def create_dataloaders(X, y, batch_size=64):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create PyTorch datasets\n",
    "    train_dataset = ChessDataset(X_train, y_train)\n",
    "    val_dataset = ChessDataset(X_val, y_val)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Example usage\n",
    "training_csv = 'path/to/training_data.csv'\n",
    "labels_csv = 'path/to/labels_data.csv'\n",
    "\n",
    "X, y = load_and_preprocess_data(training_csv, labels_csv)\n",
    "train_loader, val_loader = create_dataloaders(X, y)\n",
    "\n",
    "# Now `train_loader` and `val_loader` are ready to be used in a training loop with PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchPlay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
