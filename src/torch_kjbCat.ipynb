{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PyLinq import PyLinqData\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Move tensor to the GPU\n",
    "x = torch.tensor([1.0])\n",
    "x = x.to(device)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to train a simple neural network with an \n",
    "# input layer of 71 doubles and middle layer of 101 doubles and an output layer of 71 doubles\n",
    "# we will use the sigmoid function as the activation function\n",
    "# we will use the mean squared error as the loss function\n",
    "# we will use the stochastic gradient descent as the optimization algorithm\n",
    "# we will use the learning rate of 0.01\n",
    "# we will use the batch size of 100\n",
    "# we will use the number of epochs of 100\n",
    "# we will use the random seed of 42\n",
    "# will import the training dat from the file \"x_training.csv\" in the same folder as this notebook\n",
    "# will import the target data from the file \"y_labels.csv\" in the same folder as this notebook\n",
    "# we will save the trained model to the file \"model.pt\" in the same folder as this notebook\n",
    "# we will save the loss history to the file \"loss_history.csv\" in the same folder as this notebook\n",
    "# we will save the accuracy history to the file \"accuracy_history.csv\" in the same folder as this notebook\n",
    "# we will save the training history to the file \"training_history.csv\" in the same folder as this notebook\n",
    "# we will save the validation history to the file \"validation_history.csv\" in the same folder as this notebook\n",
    "# we will save the test history to the file \"test_history.csv\" in the same folder as this notebook\n",
    "# we will save the confusion matrix to the file \"confusion_matrix.csv\" in the same folder as this notebook\n",
    "\n",
    "# import the libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set the random seed\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# load the data\n",
    "x = pd.read_csv(\"../x_training.csv\")\n",
    "y = pd.read_csv(\"../y_labels.csv\")\n",
    "\n",
    "# The training data consists of doubles.  The first 64 columns of input data have only a few possible values.  Examine the first 64 columns and find out all the possible values that can be found in those columns.\n",
    "uniqueValus = x.iloc[:, 0:64].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the unique values with some explanation of what they are and their frequency in each of the 64 columns\n",
    "print(\"The first 64 columns of the input data have the following unique values\")\n",
    "# create a concatenation of the input to the output data in a separate 2D numpy array\n",
    "x = x.to_numpy()\n",
    "y = y.to_numpy()\n",
    "# concatenate x and y into a single 2D numpy array\n",
    "data = np.concatenate((x, y), axis=1)\n",
    "# make sure the data is in the correct format\n",
    "data = data.astype(float)\n",
    "\n",
    "# # convert the data into ordinal encoding for all columns\n",
    "# for i in range(0, 71):\n",
    "#     uniqueValues = np.unique(data[:, i]) # this line finds the unique values in the column\n",
    "#     for j in range(0, len(uniqueValues)):\n",
    "#         data[:, i] = np.where(data[:, i] == uniqueValues[j], j, data[:, i])\n",
    "\n",
    "# # validate the conversion by converting the data back to the original values and comparing the original and converted data\n",
    "# for i in range(0, 71):\n",
    "#     uniqueValues = np.unique(x[:, i])\n",
    "#     for j in range(0, len(uniqueValues)):\n",
    "#         x[:, i] = np.where(x[:, i] == j, uniqueValues[j], x[:, i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(uniqueValues)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train an autoencoder to reduce the dimensionality of the input data\n",
    "# the input data has 71 columns\n",
    "# the output data has 71 columns\n",
    "# the middle layer has 44 columns\n",
    "# the activation function is the sigmoid function\n",
    "# the loss function is the mean squared error\n",
    "# the optimization algorithm is the stochastic gradient descent\n",
    "# the learning rate is 0.05 and the batch size is 100\n",
    "# the number of epochs is 100\n",
    "# the random seed is 42\n",
    "# the model is saved to the file \"autoencoder.pt\"\n",
    "# the loss history is saved to the file \"autoencoder_loss_history.csv\"\n",
    "\n",
    "# create the autoencoder class\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(71, 500),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(500, 71),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# create the autoencoder\n",
    "autoencoder = Autoencoder()\n",
    "autoencoder.to(device)\n",
    "\n",
    "# create the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# create the optimizer\n",
    "optimizer = optim.SGD(autoencoder.parameters(), lr=0.04)\n",
    "\n",
    "# create the data loader\n",
    "dataLoader = torch.utils.data.DataLoader(x, batch_size=100, shuffle=True)\n",
    "\n",
    "# train the autoencoder\n",
    "lossHistory = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(1000):\n",
    "    for i, data in enumerate(dataLoader, 0):\n",
    "        inputs = data\n",
    "        inputs = inputs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = autoencoder(inputs.float())\n",
    "        loss = criterion(outputs.float(), inputs.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    lossHistory.append(loss.item())\n",
    "    print(\"Epoch: \", epoch, \" Loss: \", loss.item())\n",
    "\n",
    "# save the autoencoder\n",
    "torch.save(autoencoder.state_dict(), \"autoencoder.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the loss history\n",
    "lossHistory = pd.DataFrame(lossHistory, columns=[\"Loss\"])\n",
    "\n",
    "lossHistory.to_csv(\"autoencoder_loss_history.csv\", index=False)\n",
    "\n",
    "# plot the loss history\n",
    "plt.plot(lossHistory)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Autoencoder Loss History\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a random single input from the input data and use the trained autoencoder to encode and decode the input\n",
    "# print the original input and the encoded and decoded input\n",
    "# choose a random input\n",
    "input = x[0, :]\n",
    "# encode and decode the input\n",
    "input = torch.tensor(input)\n",
    "input = input.to(device)\n",
    "output = autoencoder(input.float())\n",
    "output = output.cpu().detach().numpy()\n",
    "input = input.cpu().detach().numpy()\n",
    "print(\"Original Input: \", input)\n",
    "print(\"Output: \", output)   \n",
    "\n",
    "# train a neural network to classify the input data\n",
    "# the input data has 71 columns\n",
    "# the output data has 71 columns\n",
    "# the middle layer has 101 columns\n",
    "# the activation function is the sigmoid function\n",
    "# the loss function is the mean squared error\n",
    "# the optimization algorithm is the stochastic gradient descent\n",
    "# the learning rate is 0.01 and the batch size is 100\n",
    "# the number of epochs is 500\n",
    "# the random seed is 42\n",
    "# the model is saved to the file \"model.pt\"\n",
    "\n",
    "# create the neural network class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(71, 101)\n",
    "        self.layer2 = nn.Linear(101, 71)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "# create the neural network\n",
    "neuralNetwork = NeuralNetwork()\n",
    "neuralNetwork.to(device)\n",
    "\n",
    "# create the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# create the optimizer\n",
    "optimizer = optim.SGD(neuralNetwork.parameters(), lr=0.11)\n",
    "\n",
    "# create the data loader\n",
    "dataLoader = torch.utils.data.DataLoader(x, batch_size=100, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train the neural network\n",
    "lossHistory = []\n",
    "for epoch in range(500):\n",
    "    for i, data in enumerate(dataLoader, 0):\n",
    "        inputs = data\n",
    "        inputs = inputs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = neuralNetwork(inputs.float())\n",
    "        loss = criterion(outputs.float(), inputs.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    lossHistory.append(loss.item())\n",
    "    print(\"Epoch: \", epoch, \" Loss: \", loss.item())\n",
    "\n",
    "# save the neural network\n",
    "torch.save(neuralNetwork.state_dict(), \"model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the loss history\n",
    "lossHistory = pd.DataFrame(lossHistory, columns=[\"Loss\"])\n",
    "lossHistory.to_csv(\"loss_history.csv\", index=False)\n",
    "\n",
    "# plot the loss history\n",
    "plt.plot(lossHistory)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss History\")\n",
    "plt.show()\n",
    "\n",
    "# choose a random single input from the input data and use the trained neural network to predict the output\n",
    "# print the original input and the predicted output\n",
    "# choose a random input\n",
    "input = x[0, :]\n",
    "# predict the output\n",
    "input = torch.tensor(input)\n",
    "\n",
    "input = input.to(device)\n",
    "output = neuralNetwork(input.float())\n",
    "output = output.cpu().detach().numpy()\n",
    "input = input.cpu().detach().numpy()\n",
    "print(\"Original Input: \", input)\n",
    "print(\"Output: \", output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinate_to_index(coordinate):\n",
    "    # Convert the file into a 0-based index (a=0, b=1, ..., h=7)\n",
    "    file = ord(coordinate[0].lower()) - ord('a')\n",
    "    # Convert the rank into a 0-based index (8=0, 7=1, ..., 1=7)\n",
    "    rank = 8 - int(coordinate[1])\n",
    "    # Calculate the index in the uncompressed FEN string\n",
    "    return rank * 8 + file\n",
    "\n",
    "# define the function to add the enpassant target rows\n",
    "def addEnpassantTargets(origRow, fen, i):\n",
    "    # create a string to represent the row\n",
    "    # throw an error if i is not 2 or 6\n",
    "    if(i != 2 and i != 5):\n",
    "        raise ValueError(\"i must be 2 or 6\")\n",
    "    row = origRow\n",
    "    if(fen[3] != \"-\"):\n",
    "        if(int(fen[3][1]) == i + 1 or int(fen[3][1]) == i):\n",
    "            cols = \"abcdefgh\"\n",
    "            index = cols.index(fen[3][0])\n",
    "            # use the simplest notation to replace the character at the index with the t character\n",
    "            row = row[:index] + (\"T\" if i == 2 else \"t\") + row[index + 1:]\n",
    "    # set row to the 8 char substring of all starting at side * 8\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  KQkq  Converted:  KQkq  Reverted:  KQkq\n",
      "Original:  Kkq  Converted:  K-kq  Reverted:  Kkq\n",
      "Original:  KQk  Converted:  KQk-  Reverted:  KQk\n",
      "Original:  KQ  Converted:  KQ--  Reverted:  KQ\n",
      "Original:  K  Converted:  K---  Reverted:  K\n",
      "Original:  Q  Converted:  -Q--  Reverted:  Q\n",
      "Original:  k  Converted:  --k-  Reverted:  k\n",
      "Original:  q  Converted:  ---q  Reverted:  q\n",
      "Original:  -  Converted:  ----  Reverted:  -\n"
     ]
    }
   ],
   "source": [
    "def castlingRightsToString(castlingRights):\n",
    "    # Define the order of castling rights as they should appear in the string\n",
    "    orderedRights = \"KQkq\"\n",
    "    # Use list comprehension to check for each right in orderedRights and replace with \"-\" if absent\n",
    "    return ''.join(c if c in castlingRights else '-' for c in orderedRights)\n",
    "\n",
    "def revertCastlingRights(paddedRights):\n",
    "    # Filter out '-' characters and join the remaining characters to form the castling rights part of FEN\n",
    "    castlingRights = ''.join(c for c in paddedRights if c != '-')\n",
    "    # Return a dash if there are no castling rights, otherwise return the castling rights string\n",
    "    return castlingRights if castlingRights else '-'\n",
    "\n",
    "# test these functions with a variety of inputs such as KQkq, Kkq, KQk, KQ, K, Q, k, q, and the empty string\n",
    "# create a list of standard FEN castling rights strings which are variable length\n",
    "castlingRights = [\"KQkq\", \"Kkq\", \"KQk\", \"KQ\", \"K\", \"Q\", \"k\", \"q\", \"-\"]\n",
    "# use the map function to apply the function to each element of the list and then back again and compare the final result with the original\n",
    "# loop through each string in the list and outpt the result of the function and the original string to the console\n",
    "convertedRights = list(map(castlingRightsToString, castlingRights))\n",
    "revertedRights = list(map(revertCastlingRights, convertedRights))\n",
    "# go throough each string in the list and print the original string and the result of the function in detail\n",
    "for i in range(len(castlingRights)):\n",
    "    print(\"Original: \", castlingRights[i], \" Converted: \", convertedRights[i], \" Reverted: \", revertedRights[i])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generate some new categorical data for a new neural network\n",
    "# the new data has enough columns to represent a variation of FEN notation for a chess board, where the / is left out because\n",
    "# each row is represented in full without any compression of the empty squares\n",
    "# here is an example of a normal FEN notation: rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n",
    "# define a function to take the normal notation and convert it to a 64 column representation without slashes plus\n",
    "# The full move and half move counts are discarded, but the move turn and castling rights are preserved\n",
    "# here is an example of the conversion of the starting position: rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1 to the new format\n",
    "# rnbqkbnrpppppppp00000000000000000000000000000000PPPPPPPPRNBQKBNRwKQkq\n",
    "# the first 64 columns represent the board, and the last 5 columns represent the move turn and castling rights\n",
    "# the new data has 69 columns\n",
    "def convertFEN(fen):\n",
    "    # split the FEN into its 6 components\n",
    "    fen = fen.split(\" \")\n",
    "    # split the board into its 8 rows\n",
    "    board = fen[0].split(\"/\")\n",
    "    # create a new board with the rows combined and the empty squares compressed\n",
    "    newBoard = \"\"\n",
    "    for i in range(0, 8):\n",
    "        # call a function to add the enpassant target rows if i has the value of 2 or 5\n",
    "        for j in range(0, len(board[i])):\n",
    "            if board[i][j].isdigit():\n",
    "                for k in range(0, int(board[i][j])):\n",
    "                    newBoard += \"0\"\n",
    "            else:\n",
    "                newBoard += board[i][j]\n",
    "        # if i == 2 or i == 5:\n",
    "        #     # pass the last 8 chars of newBoard into the enpassant function, then replace the last 8 chars of newBoard with the result\n",
    "        #     newBoard = newBoard[:-8] + addEnpassantTargets(newBoard[-8:], fen, i)\n",
    "            \n",
    "    if fen[3] != \"-\":\n",
    "        index = coordinate_to_index(fen[3])\n",
    "        if fen[3][1] == \"3\":\n",
    "            newBoard = newBoard[:index - 8] + \"T\" + newBoard[index - 7:]\n",
    "        else:\n",
    "            newBoard = newBoard[:index + 8] + \"t\" + newBoard[index + 9:]\n",
    "\n",
    "    # add the columns for move turn and castling rights\n",
    "    newBoard += fen[1] + castlingRightsToString(fen[2])\n",
    "    return newBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revertFEN(custom_fen):\n",
    "    # Find the en passant target and replace 't' or 'T' with '0'\n",
    "    en_passant_target = '-'\n",
    "    if 'T' in custom_fen or 't' in custom_fen:\n",
    "        en_passant_char = 'T' if 'T' in custom_fen else 't'\n",
    "        en_passant_target_index = custom_fen.index(en_passant_char)\n",
    "        # Convert the index to a coordinate\n",
    "        file = chr((en_passant_target_index % 8) + ord('a'))\n",
    "        rank = str(8 - (en_passant_target_index // 8))\n",
    "        en_passant_target = file + rank\n",
    "        # Replace 't' or 'T' with '0'\n",
    "        custom_fen = custom_fen[:en_passant_target_index] + '0' + custom_fen[en_passant_target_index+1:]\n",
    "\n",
    "    # Initialize an empty list to hold the standard FEN ranks\n",
    "    ranks = []\n",
    "    # Process each rank in the custom FEN\n",
    "    for rank_start in range(0, 64, 8):\n",
    "        # Extract the current rank\n",
    "        rank = custom_fen[rank_start:rank_start + 8]\n",
    "        # Replace zeros with the appropriate number of empty squares\n",
    "        standard_rank = ''\n",
    "        empty_count = 0\n",
    "        for char in rank:\n",
    "            if char == '0':\n",
    "                empty_count += 1\n",
    "            else:\n",
    "                if empty_count > 0:\n",
    "                    standard_rank += str(empty_count)\n",
    "                    empty_count = 0\n",
    "                standard_rank += char\n",
    "        if empty_count > 0:\n",
    "            standard_rank += str(empty_count)\n",
    "        # Add the processed rank to the list\n",
    "        ranks.append(standard_rank)\n",
    "    # Join the ranks with slashes to form the piece placement part of the standard FEN\n",
    "    piece_placement = '/'.join(ranks)\n",
    "    # Extract the remaining parts of the custom FEN\n",
    "    move_turn = custom_fen[64]\n",
    "    castling_rights = custom_fen[65:69].replace('-', '')\n",
    "    # If there are no castling rights, represent with a dash\n",
    "    castling_rights = castling_rights if castling_rights else '-'\n",
    "    # Assemble the standard FEN\n",
    "    return f\"{piece_placement} {move_turn} {castling_rights} {en_passant_target}\"\n",
    "\n",
    "# Test the revertFEN function with the given custom FEN\n",
    "standard_fen = \"r1bqkbnr/ppp1pppp/n7/3pP3/8/8/PPPP1PPP/RNBQKBNR w KQkq d6 0 3\"\n",
    "custom_fen = convertFEN(standard_fen)\n",
    "indexOfEnpassant = coordinate_to_index('d6')\n",
    "characterAtIndex = custom_fen[indexOfEnpassant]\n",
    "rev_custom_fen = revertFEN(custom_fen)\n",
    "\n",
    "assert len(custom_fen) == 69 # 64 for the board, 1 for move turn, 4 for castling rights\n",
    "assert custom_fen[indexOfEnpassant] == 't'\n",
    "assert rev_custom_fen in standard_fen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0bqkbnrppp0ppppn0000000000pP00000000000000t0000PPPP0PPPRNBQKBNRwKQkq\n",
      "r0bqkbnrppp0p0ppn00P00T00000000000000pP0N0000000PPPP0P0PR0BQKBNRbKQkq\n",
      "rnbqkbnrpppppppp00000000000000000000000000000000PPPPPPPPRNBQKBNRwKQkq\n",
      "00kr0bnrpppqp0ppn00P000000000b00000P0B00N00000p0PPPQ0P0PR000KBNRwKQ--\n"
     ]
    }
   ],
   "source": [
    "# test the function on the starting position\n",
    "# test with a different FEN where a move sequence E2E4, etc that leads to a board position where enpassant is possible\n",
    "fen1 = \"r1bqkbnr/ppp1pppp/n7/3pP3/8/8/PPPP1PPP/RNBQKBNR w KQkq d6 0 3\"\n",
    "newBoard1 = convertFEN(fen1)\n",
    "print(newBoard1)\n",
    "\n",
    "fen2 = \"r1bqkbnr/ppp1p1pp/n2P4/8/5pP1/N7/PPPP1P1P/R1BQKBNR b KQkq g3 0 5\"\n",
    "newBoard2 = convertFEN(fen2)\n",
    "print(newBoard2)\n",
    "\n",
    "fen3 = \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\"\n",
    "newBoard3 = convertFEN(fen3)\n",
    "print(newBoard3)\n",
    "\n",
    "fen4 = \"2kr1bnr/pppqp1pp/n2P4/5b2/3P1B2/N5p1/PPPQ1P1P/R3KBNR w KQ - 5 9\"\n",
    "newBoard4 = convertFEN(fen4)\n",
    "print(newBoard4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           CustomFEN\n",
      "0  rnbqkbnrpppppppp000000000000000000000000000000...\n",
      "1  rnbqkbnrpppppppp00000000000000000000P000000000...\n",
      "2  r0bqkbnrppppppppn0000000000000000000P000000000...\n",
      "3  r0bqkbnrppppppppn00000000000P00000000000000000...\n",
      "4  r0bqkbnrppp0ppppn0000000000pP00000000000000t00...\n",
      "                                           CustomFEN\n",
      "0  rnbqkbnrpppppppp00000000000000000000P000000000...\n",
      "1  r0bqkbnrppppppppn0000000000000000000P000000000...\n",
      "2  r0bqkbnrppppppppn00000000000P00000000000000000...\n",
      "3  r0bqkbnrppp0ppppn0000000000pP00000000000000t00...\n",
      "4  r0bqkbnrppp0ppppn00P00000000000000000000000000...\n"
     ]
    }
   ],
   "source": [
    "#!pip install python-chess\n",
    "import chess\n",
    "import chess.pgn\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Assuming convertFEN is defined as before and working correctly\n",
    "\n",
    "# Sample PGN string for demonstration\n",
    "pgn_string = \"\"\"\n",
    "[Event \"NicosiaKyrenia's Study: Enpassant\"]\n",
    "[Site \"https://lichess.org/study/WCSL1Ul1/YZoxPnWI\"]\n",
    "[Result \"*\"]\n",
    "[Variant \"Standard\"]\n",
    "[ECO \"B00\"]\n",
    "[Opening \"Lemming Defense\"]\n",
    "[Annotator \"https://lichess.org/@/NicosiaKyrenia\"]\n",
    "[UTCDate \"2024.02.18\"]\n",
    "[UTCTime \"01:03:04\"]\n",
    "\n",
    "1. e4 Na6 2. e5 d5 3. exd6 f5 4. Na3 f4 5. g4 fxg3 *\n",
    "\"\"\"\n",
    "\n",
    "# Initialize pandas DataFrames for training data and labels\n",
    "training_data = pd.DataFrame(columns=['CustomFEN'])\n",
    "labels_data = pd.DataFrame(columns=['CustomFEN'])\n",
    "\n",
    "# Read the PGN\n",
    "pgn = io.StringIO(pgn_string)\n",
    "game = chess.pgn.read_game(pgn)\n",
    "\n",
    "# Initialize a board from the game\n",
    "board = game.board()\n",
    "\n",
    "for move in game.mainline_moves():\n",
    "    # Generate standard FEN before the move\n",
    "    fen_before = board.fen()\n",
    "    # Convert to custom FEN and store as training data\n",
    "    custom_fen_before = convertFEN(fen_before)\n",
    "    training_data = pd.concat([training_data, pd.DataFrame({'CustomFEN': [custom_fen_before]})], ignore_index=True)\n",
    "    \n",
    "    # Apply the move on the board\n",
    "    board.push(move)\n",
    "    \n",
    "    # Generate standard FEN after the move\n",
    "    fen_after = board.fen()\n",
    "    # Convert to custom FEN and store as label data\n",
    "    custom_fen_after = convertFEN(fen_after)\n",
    "    labels_data = pd.concat([labels_data, pd.DataFrame({'CustomFEN': [custom_fen_after]})], ignore_index=True)\n",
    "    # custom_fen_after = convertFEN(fen_after)\n",
    "    # labels_data = labels_data.append({'CustomFEN': custom_fen_after}, ignore_index=True)\n",
    "\n",
    "# For demonstration, print the first few rows of each DataFrame\n",
    "print(training_data.head())\n",
    "print(labels_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 square possibilities: ['R', 'N', 'B', 'Q', 'K', 'r', 'n', 'b', 'q', 'k', '0']\n",
      "Move turn possibilities: ['w', 'b']\n",
      "First castling right possibility (King-side for white): ['K', '-']\n"
     ]
    }
   ],
   "source": [
    "# This the following commented code is the general approach to go through the \n",
    "# training data and labels and convert the data to ordinal encoding\n",
    "# convert the data into ordinal encoding for all columns\n",
    "# for i in range(0, 69):\n",
    "#     uniqueValues = np.unique(training_data.iloc[:, i]) # this line finds the unique values in the column\n",
    "#     for j in range(0, len(uniqueValues)):\n",
    "#         training_data.iloc[:, i] = np.where(training_data.iloc[:, i] == uniqueValues[j], j, training_data.iloc[:, i])\n",
    "#         labels_data.iloc[:, i] = np.where(labels_data.iloc[:, i] == uniqueValues[j], j, labels_data.iloc[:, i])\n",
    "\n",
    "# however, it is possible to synthesize the possible unique values for each column keeping in mind these rules:\n",
    "# There are no pawns possible in rows 1 and 8\n",
    "# Bishops can only be only be in the same color square as the starting square (not sure if that will help with ordinal encoding)\n",
    "# There are only a few possible values for the castling rights and the move turn\n",
    "# The enpassant target can only be in rows 3 and 6\n",
    "# The enpassant target can only be in the same chess board column as the last move's pawn move (not sure if that will help with ordinal encoding)\n",
    "# define a function to synthesize the possible unique values for each column of the training data and labels\n",
    "# the function will return a list of the possible unique values for each column (don't know why it would be a list of lists)\n",
    "# the function uniqueValuesPossibleForColumn will take a record and the column index as input and return the possible unique values for that column\n",
    "# for i in range(0, 69):\n",
    "#     uniqueValues = uniqueValuesPossibleForColumn(training_data.iloc[0, :], i)\n",
    "\n",
    "def synthesize_custom_ordinal_values_final():\n",
    "    ordinal_values = {}\n",
    "\n",
    "    # Define all possible pieces, including uppercase for white and lowercase for black\n",
    "    pieces_general = ['R', 'N', 'B', 'Q', 'K', 'P', 'r', 'n', 'b', 'q', 'k', 'p', '0']\n",
    "    pieces_no_pawns = ['R', 'N', 'B', 'Q', 'K', 'r', 'n', 'b', 'q', 'k', '0']  # Exclude pawns in rows 1 and 8\n",
    "    pieces_en_passant = ['R', 'N', 'B', 'Q', 'K', 'P', 'r', 'n', 'b', 'q', 'k', 'p', '0', 'T', 't']  # Include 't' for en passant\n",
    "    \n",
    "    # Assign possible values for each board square\n",
    "    for i in range(64):\n",
    "        row = i // 8 + 1\n",
    "        if row in [1, 8]:\n",
    "            ordinal_values[i] = pieces_no_pawns\n",
    "        elif row in [3, 6]:  # Corrected rows for potential en passant targets, reflecting actual play possibilities\n",
    "            ordinal_values[i] = pieces_en_passant\n",
    "        else:\n",
    "            ordinal_values[i] = pieces_general\n",
    "\n",
    "    # Move turn possibilities\n",
    "    ordinal_values[64] = ['w', 'b']\n",
    "    \n",
    "    # Castling rights - specific to each right, with '-' indicating the absence of the right\n",
    "    ordinal_values[65] = ['K', '-']  # King-side for white\n",
    "    ordinal_values[66] = ['Q', '-']  # Queen-side for white\n",
    "    ordinal_values[67] = ['k', '-']  # King-side for black\n",
    "    ordinal_values[68] = ['q', '-']  # Queen-side for black\n",
    "    \n",
    "    return ordinal_values\n",
    "\n",
    "ordinal_values_final = synthesize_custom_ordinal_values_final()\n",
    "\n",
    "# Example of accessing possible values for specific squares or data points\n",
    "print(\"A1 square possibilities:\", ordinal_values_final[0])  # Example for A1 square\n",
    "print(\"Move turn possibilities:\", ordinal_values_final[64]) # Example for move turn\n",
    "print(\"First castling right possibility (King-side for white):\", ordinal_values_final[65]) # Example for first castling right\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test some of the custom FENs with the ordinal encoding to make sure the encoding is working correctly\n",
    "# for each custom FEN, go through each character and confirm that the character is in the possible unique values for that column\n",
    "# if it is not, print an error message\n",
    "\n",
    "for fen in [newBoard1, newBoard2, newBoard3, newBoard4]:\n",
    "    for i, char in enumerate(fen):\n",
    "        if char not in ordinal_values_final[i]:\n",
    "            print(f\"Error: {char} not in possible values for column {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# # Placeholder for the convertFEN function you provided earlier\n",
    "# def convertFEN(fen):\n",
    "#     # Your convertFEN function here\n",
    "#     custom_fen = convertFEN(fen)\n",
    "#     return custom_fen\n",
    "\n",
    "# Function to encode a custom FEN string to numerical format\n",
    "def encode_custom_fen(custom_fen):\n",
    "    # Implement the encoding logic here, using the ordinal_values mapping\n",
    "    # This is a placeholder function; you'll need to replace it with your actual encoding logic\n",
    "    # encoded = np.array([ordinal_values[char] for char in custom_fen])\n",
    "    # define a dictionary to hold the ordinal values for each piece.  Use negative numbers for black, and positive for white.\n",
    "    # pawns are 1, knights are 3, bishops 3.5, rooks 5, queens 9, and kings 15\n",
    "    pieceValues = {'R': 5, 'N': 3, 'B': 3.5, 'Q': 9, 'K': 15, 'P': 1, 'T': 1.3, 'r': -5, 'n': -3, 'b': -3.5, 'q': -9, 'k': -15, 'p': -1, 't': -1.3, '0': 0}\n",
    "    moveTurn = {'w': 1, 'b': -1}\n",
    "    # in general castlingRights = {'K': 1, 'Q': 1, 'k': -1, 'q': -1, '-': 0}\n",
    "    # however it needs to be split into 4 separate dictionaries\n",
    "    castlingRights1 = {'K': 1, '-': 0}\n",
    "    castlingRights2 = {'Q': 1, '-': 0}\n",
    "    castlingRights3 = {'k': -1, '-': 0}\n",
    "    castlingRights4 = {'q': -1, '-': 0}\n",
    "    # convert the custom FEN to a list of floats in a numpy array\n",
    "    encoded = (np.array([pieceValues[char] for char in custom_fen[:64]] + \n",
    "                        [moveTurn[custom_fen[64]]] + \n",
    "                        [castlingRights1[char] for char in custom_fen[65]] +\n",
    "                        [castlingRights2[char] for char in custom_fen[66]] +\n",
    "                        [castlingRights3[char] for char in custom_fen[67]] +\n",
    "                        [castlingRights4[char] for char in custom_fen[68]]))\n",
    "    # make sure its a float array\n",
    "    encoded = encoded.astype(float)    \n",
    "\n",
    "    return encoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unencode_custom_fen(encoded_custom_fen):\n",
    "    # Implement the decoding logic here, using the ordinal_values mapping\n",
    "    # This is a placeholder function; you'll need to replace it with your actual decoding logic\n",
    "    # decoded = np.array([ordinal_values[char].index(char) for char in custom_fen])\n",
    "    # define a dictionary to hold the ordinal values for each piece.  Use negative numbers for black, and positive for white.\n",
    "    # pawns are 1, knights are 3, bishops 3.5, rooks 5, queens 9, and kings 15\n",
    "    pieceValues = {5: 'R', 3: 'N', 3.5: 'B', 9: 'Q', 15: 'K', 1: 'P', 1.3: 'T', -5: 'r', -3: 'n', -3.5: 'b', -9: 'q', -15: 'k', -1: 'p', -1.3: 't', 0: '0'}\n",
    "    moveTurn = {1: 'w', -1: 'b'}\n",
    "    # in general castlingRights = {1: 'K', 1: 'Q', -1: 'k', -1: 'q', 0: '-'}\n",
    "    # but must be split into 4 separate dictionaries\n",
    "    castlingRights1 = {1: 'K', 0: '-'}\n",
    "    castlingRights2 = {1: 'Q', 0: '-'}\n",
    "    castlingRights3 = {-1: 'k', 0: '-'}\n",
    "    castlingRights4 = {-1: 'q', 0: '-'}\n",
    "\n",
    "    # manually loop and convert the floats to the correct characters\n",
    "    decoded = \"\"\n",
    "    for i in range(0, 64):\n",
    "        decoded += pieceValues[encoded_custom_fen[i]]\n",
    "    decoded += moveTurn[encoded_custom_fen[64]]\n",
    "    decoded += castlingRights1[encoded_custom_fen[65]]\n",
    "    decoded += castlingRights2[encoded_custom_fen[66]]\n",
    "    decoded += castlingRights3[encoded_custom_fen[67]]\n",
    "    decoded += castlingRights4[encoded_custom_fen[68]]\n",
    "                              \n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'revertFEN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m custEncConvSecondFEN \u001b[38;5;241m=\u001b[39m unencode_custom_fen(encConvSecondFEN)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# convert them back to a FENs\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m regFirstFEN \u001b[38;5;241m=\u001b[39m \u001b[43mrevertFEN\u001b[49m(custEncConvFirstFEN)\n\u001b[0;32m     71\u001b[0m regSecondFEN \u001b[38;5;241m=\u001b[39m revertFEN(custEncConvSecondFEN)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# compare the original FEN with the new FEN.  If the new FEN is not \u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# contained in the original FEN, increment badCount and add the index to the list\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# define a boolean to see if the new FEN is contained in the original FEN\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'revertFEN' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "def load_and_preprocess_data(training_csv, labels_csv):\n",
    "    # Load the CSV files\n",
    "    training_df = pd.read_csv(training_csv)\n",
    "    labels_df = pd.read_csv(labels_csv)\n",
    "    \n",
    "    # Convert FEN strings to custom format and then encode\n",
    "    training_data_encoded = [encode_custom_fen(convertFEN(fen)) for fen in training_df['FEN']]\n",
    "    labels_encoded = [encode_custom_fen(convertFEN(fen)) for fen in labels_df['FEN']]\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X = torch.tensor(training_data_encoded, dtype=torch.float32)\n",
    "    y = torch.tensor(labels_encoded, dtype=torch.float32)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def create_dataloaders(X, y, batch_size=64):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create PyTorch datasets\n",
    "    train_dataset = ChessDataset(X_train, y_train)\n",
    "    val_dataset = ChessDataset(X_val, y_val)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "# load csv called ../X_training_Y_Labels_Comment.csv and save the first column as training_data.csv and \n",
    "# the second column as labels_data.csv\n",
    "\n",
    "# Load and preprocess the data, may be able to comment out after initial run\n",
    "training_csv = '..\\X_training_Y_Labels_Comment.csv'\n",
    "# read it into numpy or pandas\n",
    "training_df = pd.read_csv(training_csv)\n",
    "\n",
    "# loop manually through each record to spot any anomalies\n",
    "badCount = 0\n",
    "indexListOfBad = []\n",
    "for i in range(0, len(training_df)):\n",
    "    # don't print anything unless there is an anomaly\n",
    "    # convert each FEN, 2 per record, to a custom FEN and then encode it\n",
    "    # each record consist of 2 FENs, the first is the input and the second is the output\n",
    "    # extract the first FEN\n",
    "    firstFEN = training_df.iloc[i, 0]\n",
    "    # and the second FEN\n",
    "    secondFEN = training_df.iloc[i, 1]\n",
    "    # convert the first FEN to a custom FEN and then encode it\n",
    "    convFirstFEN = convertFEN(firstFEN)\n",
    "    encConvFirstFEN = encode_custom_fen(convFirstFEN)\n",
    "    # convert the second FEN to a custom FEN and then encode it\n",
    "    convSecondFEN = convertFEN(secondFEN)\n",
    "    encConvSecondFEN = encode_custom_fen(convSecondFEN)\n",
    "    # convert encConvFirstFEN and encConvSecondFEN back to custom FENs\n",
    "    custEncConvFirstFEN = unencode_custom_fen(encConvFirstFEN)\n",
    "    custEncConvSecondFEN = unencode_custom_fen(encConvSecondFEN)\n",
    "    # convert them back to a FENs\n",
    "    regFirstFEN = revertFEN(custEncConvFirstFEN)\n",
    "    regSecondFEN = revertFEN(custEncConvSecondFEN)\n",
    "    # compare the original FEN with the new FEN.  If the new FEN is not \n",
    "    # contained in the original FEN, increment badCount and add the index to the list\n",
    "    # define a boolean to see if the new FEN is contained in the original FEN\n",
    "    firstFENContained = regFirstFEN in firstFEN\n",
    "    secondFENContained = regSecondFEN in secondFEN\n",
    "    # if either is false increment badCount and add the index to the list\n",
    "    if not firstFENContained or not secondFENContained:\n",
    "        # TODO remove test code\n",
    "        regSecondFEN = revertFEN(custEncConvSecondFEN)\n",
    "\n",
    "        badCount += 1\n",
    "        indexListOfBad.append(i)\n",
    "    # of bad indices.  once done looping remove the bad records from the dataframe\n",
    "    # and print the bad count and the list of bad indices\n",
    "\n",
    "print(\"The number of bad records is: \", badCount)\n",
    "print(\"The list of bad indices is: \", indexListOfBad)\n",
    "# remove the bad records from the dataframe\n",
    "training_df = training_df.drop(indexListOfBad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the first column as training_data.csv\n",
    "training_df.iloc[:, 0].to_csv('training_data.csv', index=False)\n",
    "# save the second column as labels_data.csv\n",
    "training_df.iloc[:, 1].to_csv('labels_data.csv', index=False)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "training_csv = 'training_data.csv'\n",
    "labels_csv = 'labels_data.csv'\n",
    "\n",
    "\n",
    "X, y = load_and_preprocess_data(training_csv, labels_csv)\n",
    "train_loader, val_loader = create_dataloaders(X, y)\n",
    "\n",
    "# Now `train_loader` and `val_loader` are ready to be used in a training loop with PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchPlay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
