{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n",
      "tensor([1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Move tensor to the GPU\n",
    "x = torch.tensor([1.0])\n",
    "x = x.to(device)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to train a simple neural network with an \n",
    "# input layer of 71 doubles and middle layer of 101 doubles and an output layer of 71 doubles\n",
    "# we will use the sigmoid function as the activation function\n",
    "# we will use the mean squared error as the loss function\n",
    "# we will use the stochastic gradient descent as the optimization algorithm\n",
    "# we will use the learning rate of 0.01\n",
    "# we will use the batch size of 100\n",
    "# we will use the number of epochs of 100\n",
    "# we will use the random seed of 42\n",
    "# will import the training dat from the file \"x_training.csv\" in the same folder as this notebook\n",
    "# will import the target data from the file \"y_labels.csv\" in the same folder as this notebook\n",
    "# we will save the trained model to the file \"model.pt\" in the same folder as this notebook\n",
    "# we will save the loss history to the file \"loss_history.csv\" in the same folder as this notebook\n",
    "# we will save the accuracy history to the file \"accuracy_history.csv\" in the same folder as this notebook\n",
    "# we will save the training history to the file \"training_history.csv\" in the same folder as this notebook\n",
    "# we will save the validation history to the file \"validation_history.csv\" in the same folder as this notebook\n",
    "# we will save the test history to the file \"test_history.csv\" in the same folder as this notebook\n",
    "# we will save the confusion matrix to the file \"confusion_matrix.csv\" in the same folder as this notebook\n",
    "\n",
    "# import the libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set the random seed\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# load the data\n",
    "x = pd.read_csv(\"../x_training.csv\")\n",
    "y = pd.read_csv(\"../y_labels.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# split the data into training, validation and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert the data to tensors\n",
    "x_train = torch.tensor(x_train.values, dtype=torch.float32)\n",
    "x_val = torch.tensor(x_val.values, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create the model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(71, 131)\n",
    "        self.layer2 = nn.Linear(131, 71)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = NeuralNetwork()\n",
    "model.to(device)\n",
    "\n",
    "# create the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# create the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create the data loaders\n",
    "train_loader = torch.utils.data.DataLoader(list(zip(x_train, y_train)), batch_size=100, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(list(zip(x_val, y_val)), batch_size=100, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(list(zip(x_test, y_test)), batch_size=100, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train the model\n",
    "loss_history = []\n",
    "accuracy_history = []\n",
    "training_history = []\n",
    "validation_history = []\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    loss_history.append(running_loss / len(train_loader))\n",
    "    accuracy_history.append(correct / total)\n",
    "    training_history.append(correct / total)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predicted = torch.round(outputs)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    validation_history.append(correct / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the model\n",
    "torch.save(model, \"model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the loss history\n",
    "loss_history = pd.DataFrame(loss_history, columns=[\"loss\"])\n",
    "loss_history.to_csv(\"loss_history.csv\", index=False)\n",
    "\n",
    "# save the accuracy history\n",
    "accuracy_history = pd.DataFrame(accuracy_history, columns=[\"accuracy\"])\n",
    "accuracy_history.to_csv(\"accuracy_history.csv\", index=False)\n",
    "\n",
    "# save the training history\n",
    "training_history = pd.DataFrame(training_history, columns=[\"training\"])\n",
    "training_history.to_csv(\"training_history.csv\", index=False)\n",
    "\n",
    "# save the validation history\n",
    "validation_history = pd.DataFrame(validation_history, columns=[\"validation\"])\n",
    "validation_history.to_csv(\"validation_history.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([0.3000, 0.0000, 0.6000, 0.0000, 0.0000, 0.0000, 1.2000, 0.9000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 1.2000, 0.0000, 0.0000, 0.4000, 0.0000,\n",
      "        0.6000, 0.6000, 0.0000, 1.1000, 1.2000, 1.0000, 0.2000, 0.0000, 0.0000,\n",
      "        0.6000, 0.0000, 0.0000, 1.2000, 0.8000, 0.1000, 0.6000, 0.0000, 0.0000,\n",
      "        0.0000, 1.2000, 0.0000, 0.7000, 0.4000, 0.0000, 0.6000, 0.0000, 0.0000,\n",
      "        1.1000, 1.2000, 0.0000, 0.5000, 0.6000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        1.2000, 0.0000, 0.3000, 0.6000, 0.0000, 0.0000, 0.0000, 0.0000, 1.2000,\n",
      "        0.9000, 0.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000, 2.6000],\n",
      "       device='cuda:0')\n",
      "Label: tensor([0.3000, 0.0000, 0.6000, 0.0000, 0.0000, 0.0000, 1.2000, 0.9000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 1.2000, 0.0000, 0.0000, 0.4000, 0.0000,\n",
      "        0.6000, 0.6000, 0.0000, 1.1000, 1.2000, 1.0000, 0.2000, 0.0000, 0.0000,\n",
      "        0.6000, 0.0000, 0.0000, 1.2000, 0.8000, 0.1000, 0.0000, 0.0000, 0.6000,\n",
      "        0.0000, 1.2000, 0.0000, 0.7000, 0.4000, 0.0000, 0.6000, 0.0000, 0.0000,\n",
      "        1.1000, 1.2000, 0.0000, 0.5000, 0.6000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        1.2000, 0.0000, 0.3000, 0.6000, 0.0000, 0.0000, 0.0000, 0.0000, 1.2000,\n",
      "        0.9000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000, 3.0000],\n",
      "       device='cuda:0')\n",
      "Output: tensor([0.2391, 0.4018, 0.1008, 0.0848, 0.0492, 0.0371, 0.9865, 0.8059, 0.1514,\n",
      "        0.4318, 0.1260, 0.1709, 0.0901, 0.9691, 0.2607, 0.1155, 0.2387, 0.1162,\n",
      "        0.3735, 0.5651, 0.0712, 0.9015, 0.9536, 0.6989, 0.1418, 0.1441, 0.1004,\n",
      "        0.5234, 0.1450, 0.0637, 0.9443, 0.6051, 0.0780, 0.2882, 0.1602, 0.1527,\n",
      "        0.1576, 0.9726, 0.1299, 0.6696, 0.1975, 0.5617, 0.3490, 0.0532, 0.0462,\n",
      "        0.9684, 0.9613, 0.1381, 0.0869, 0.5294, 0.2371, 0.0444, 0.0418, 0.0391,\n",
      "        0.9835, 0.1120, 0.1607, 0.6184, 0.0577, 0.0439, 0.0347, 0.0309, 0.9881,\n",
      "        0.7173, 0.0507, 0.0496, 0.0510, 0.0462, 0.0421, 0.0062, 1.0000],\n",
      "       device='cuda:0')\n",
      "Prediction: tensor([0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       device='cuda:0')\n",
      "Actual: tensor([0.3000, 0.0000, 0.6000, 0.0000, 0.0000, 0.0000, 1.2000, 0.9000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 1.2000, 0.0000, 0.0000, 0.4000, 0.0000,\n",
      "        0.6000, 0.6000, 0.0000, 1.1000, 1.2000, 1.0000, 0.2000, 0.0000, 0.0000,\n",
      "        0.6000, 0.0000, 0.0000, 1.2000, 0.8000, 0.1000, 0.0000, 0.0000, 0.6000,\n",
      "        0.0000, 1.2000, 0.0000, 0.7000, 0.4000, 0.0000, 0.6000, 0.0000, 0.0000,\n",
      "        1.1000, 1.2000, 0.0000, 0.5000, 0.6000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        1.2000, 0.0000, 0.3000, 0.6000, 0.0000, 0.0000, 0.0000, 0.0000, 1.2000,\n",
      "        0.9000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000, 3.0000],\n",
      "       device='cuda:0')\n",
      "Correct: tensor([False,  True, False,  True,  True,  True, False, False,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True, False, False,\n",
      "         True, False, False,  True, False,  True,  True, False,  True,  True,\n",
      "        False, False, False,  True,  True, False,  True, False,  True, False,\n",
      "        False, False, False,  True,  True, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False,  True, False, False,  True,  True,\n",
      "         True,  True, False, False, False, False, False, False, False,  True,\n",
      "        False], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# make one prediction chosen randomly from the test set.  Comment every line of code\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    i = np.random.randint(0, len(x_test))\n",
    "    inputs = x_test[i].to(device)\n",
    "    label = y_test[i].to(device)\n",
    "    output = model(inputs)\n",
    "    print(\"Input:\", inputs)\n",
    "    print(\"Label:\", label)\n",
    "    print(\"Output:\", output)\n",
    "    print(\"Prediction:\", torch.round(output))\n",
    "    print(\"Actual:\", label)\n",
    "    print(\"Correct:\", torch.round(output) == label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "1 columns passed, passed data had 71 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\torchPlay\\lib\\site-packages\\pandas\\core\\internals\\construction.py:934\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 934\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\torchPlay\\lib\\site-packages\\pandas\\core\\internals\\construction.py:981\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    980\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    983\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    984\u001b[0m     )\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[0;32m    986\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 1 columns passed, passed data had 71 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException details:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m             \u001b[38;5;66;03m# print(e)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m             \u001b[38;5;66;03m# raise the exception again to stop the program\u001b[39;00m\n\u001b[0;32m     25\u001b[0m             \u001b[38;5;66;03m# raise e\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredictions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m predictions\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# save the test history\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\torchPlay\\lib\\site-packages\\pandas\\core\\frame.py:782\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 782\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[0;32m    784\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[0;32m    785\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    788\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    790\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    791\u001b[0m         arrays,\n\u001b[0;32m    792\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    795\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    796\u001b[0m     )\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\torchPlay\\lib\\site-packages\\pandas\\core\\internals\\construction.py:498\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[1;32m--> 498\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    499\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\torchPlay\\lib\\site-packages\\pandas\\core\\internals\\construction.py:840\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    837\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m    838\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[1;32m--> 840\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\torchPlay\\lib\\site-packages\\pandas\\core\\internals\\construction.py:937\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    934\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m    940\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: 1 columns passed, passed data had 71 columns"
     ]
    }
   ],
   "source": [
    "\n",
    "# test the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        try:\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        except Exception as e:\n",
    "            print(\"Exception details:\")\n",
    "            # print(e)\n",
    "        try:    \n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "        # catch the exception object and use it to print details about the exception\n",
    "        except Exception as e:\n",
    "            print(\"Exception details:\")\n",
    "            # print(e)\n",
    "            # raise the exception again to stop the program\n",
    "            # raise e\n",
    "predictions = pd.DataFrame(predictions, columns=[\"predictions\"])\n",
    "predictions.to_csv(\"predictions.csv\", index=False)\n",
    "\n",
    "# save the test history\n",
    "test_history = pd.DataFrame([correct / total], columns=[\"test\"])\n",
    "test_history.to_csv(\"test_history.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the confusion matrix\n",
    "confusion_matrix = confusion_matrix(y_test, predictions)\n",
    "confusion_matrix = pd.DataFrame(confusion_matrix)\n",
    "confusion_matrix.to_csv(\"confusion_matrix.csv\", index=False)\n",
    "\n",
    "# plot the loss history\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss History\")\n",
    "plt.show()\n",
    "\n",
    "# plot the accuracy history\n",
    "plt.plot(accuracy_history)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy History\")\n",
    "plt.show()\n",
    "\n",
    "# plot the training and validation history\n",
    "plt.plot(training_history, label=\"Training\")\n",
    "plt.plot(validation_history, label=\"Validation\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation History\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# print the test history\n",
    "print(test_history)\n",
    "\n",
    "# print the confusion matrix\n",
    "print(confusion_matrix)\n",
    "\n",
    "# print the predictions\n",
    "print(predictions)\n",
    "\n",
    "# print the model\n",
    "print(model)\n",
    "\n",
    "# print the loss history\n",
    "print(loss_history)\n",
    "\n",
    "# print the accuracy history\n",
    "print(accuracy_history)\n",
    "\n",
    "# print the training history\n",
    "print(training_history)\n",
    "\n",
    "# print the validation history\n",
    "print(validation_history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchPlay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
